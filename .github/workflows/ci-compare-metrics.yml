name: Metrics Comparison and Post Comment
on:
  workflow_run:
    workflows: ["E2E Tests"]
    types: [completed]
permissions:
  contents: read
  pull-requests: write
  checks: write
jobs:
  metrics-comparison:
    name: Compare Metrics
    if: ${{ github.event.workflow_run.event == 'pull_request' && github.event.workflow_run.head_branch != 'main' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3 # v6
        with:
          ref: ${{ github.event.repository.default_branch }}

      - name: Install adm-zip
        run: npm install adm-zip

      - name: Download all metrics artifacts from triggering workflow
        id: download-artifacts
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8
        with:
          script: |
            const { owner, repo } = context.repo;
            const workflowRunId = context.payload.workflow_run.id;
            
            // List all artifacts from the triggering workflow run
            const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
              owner,
              repo,
              run_id: workflowRunId,
            });
            
            // Download and extract each artifact
            const fs = require('fs');
            const path = require('path');
            const AdmZip = require('adm-zip');
            
            for (const artifact of artifacts.data.artifacts) {
              const download = await github.rest.actions.downloadArtifact({
                owner,
                repo,
                artifact_id: artifact.id,
                archive_format: 'zip',
              });
            
              const zip = new AdmZip(Buffer.from(download.data));
              zip.extractAllTo(path.join(process.env.GITHUB_WORKSPACE, '.metrics', artifact.name), true);
              console.log(`Extracted artifact: ${artifact.name}`);
            }
            
            // Extract PR number (adapted from PDF logic)
            let prNumber = null;
            const pullRequest = await github.rest.pulls.list({
              owner,
              repo,
              head: `${context.payload.workflow_run.head_repository.full_name}:${context.payload.workflow_run.head_branch}`,
            });
            
            const prArtifactPath = path.join(process.env.GITHUB_WORKSPACE, '.metrics', 'pr_number', 'pr_number.txt');
            if (fs.existsSync(prArtifactPath)) {
              prNumber = fs.readFileSync(prArtifactPath, 'utf8').trim();
              console.log(`Found PR Number from artifact: ${prNumber}`);
            } else {
              if (pullRequest.data.length > 0) {
                prNumber = pullRequest.data[0].number;
              } else {
                // Fallback to commit SHA if needed
                const commitSha = context.payload.workflow_run.head_sha;
                const prsForCommit = await github.rest.repos.listPullRequestsAssociatedWithCommit({
                  owner,
                  repo,
                  commit_sha: commitSha,
                });
                if (prsForCommit.data.length > 0) {
                  prNumber = prsForCommit.data[0].number;
                  console.log(`Found PR via commit SHA: #${prNumber}`);
                }
              }
            }
            
            if (prNumber) {
              console.log(`Found PR Number: ${prNumber}`);
              core.setOutput('pr_number', prNumber);
            } else {
              console.log('Could not determine PR number. Skipping comment.');
              core.setFailed('Could not determine PR number for commenting.');
            }
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Install dependencies
        if: success() && steps.download-artifacts.outputs.pr_number
        run: |
          python3 -m pip install prometheus-client
          npm install @actions/core @actions/github

      - name: Compare metrics and generate summary
        if: success() && steps.download-artifacts.outputs.pr_number
        id: compare-metrics
        shell: bash
        run: |
          bash ./scripts/e2e/metrics_summary.sh
        env:
          LINK_TO_ARTIFACT: "https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}"

      - name: Upload metrics comparison report as artifact
        if: success() && steps.download-artifacts.outputs.pr_number
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6
        with:
          name: metrics-comparison-report
          path: ./.metrics/combined_summary.md
          retention-days: 30

      - name: Post PR comment with combined metrics summary
        if: (steps.compare-metrics.outputs.TOTAL_CHANGES != '0' || steps.compare-metrics.outputs.HAS_ERROR == 'true') && steps.download-artifacts.outputs.pr_number
        uses: thollander/actions-comment-pull-request@24bffb9b452ba05a4f3f77933840a6a841d1b32b # v3
        with:
          file-path: ./.metrics/combined_summary.md
          github-token: '${{ secrets.GITHUB_TOKEN }}'
          comment-tag: "## Metrics Comparison Summary"
          pr-number: ${{ steps.download-artifacts.outputs.pr_number }}

      - name: Create check run for metrics comparison
        if: success() && steps.download-artifacts.outputs.pr_number
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8
        with:
          script: |
            const { owner, repo } = context.repo;
            const headSha = context.payload.workflow_run.head_sha;
            const totalChanges = parseInt('${{ steps.compare-metrics.outputs.TOTAL_CHANGES }}' || '0');
            const hasError = '${{ steps.compare-metrics.outputs.HAS_ERROR }}' === 'true';
            const artifactLink = 'https://github.com/${{ github.repository }}/actions/runs/${{ github.event.workflow_run.id }}';
            
            let conclusion, summary, text;
            
            if (hasError) {
              conclusion = 'failure';
              summary = '❌ Metrics comparison failed';
              text = 'ERROR: No summary files were generated. Expected at least 8 diff files from CI.\n\nThis indicates a failure in the E2E test execution or metrics collection process.\n\n➡️ [View full metrics file](' + artifactLink + ')';
            } else if (totalChanges === 0) {
              conclusion = 'success';
              summary = '✅ No significant metric changes detected';
              text = `Total changes across all snapshots: ${totalChanges}\n\n➡️ [View full metrics file](${artifactLink})`;
            } else {
              conclusion = 'failure';
              summary = `❌ ${totalChanges} metric changes detected`;
              text = `Total changes across all snapshots: ${totalChanges}\n\n➡️ [View full metrics file](${artifactLink})`;
            }
            
            await github.rest.checks.create({
              owner,
              repo,
              name: 'Metrics Comparison',
              head_sha: headSha,
              status: 'completed',
              conclusion: conclusion,
              output: {
                title: 'Metrics Comparison Result',
                summary: summary,
                text: text
              }
            });
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
